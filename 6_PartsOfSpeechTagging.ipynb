{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e90d4d2",
   "metadata": {},
   "source": [
    "\n",
    "### Parts Of Speech Tags\n",
    "\n",
    "\n",
    "\"Taj Mahal is a beautiful Monument\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4634575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech Of DR APJ Abdul Kalam\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c2b5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India.', 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.', 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.', 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.', 'It is this freedom that\\n               we must protect and nurture and build on.', 'If we are not free, no one will respect us.', 'My second vision for India’s development.', 'For fifty years we have been a developing nation.', 'It is time we see ourselves as a developed nation.', 'We are among the top 5 nations of the world\\n               in terms of GDP.', 'We have a 10 percent growth rate in most areas.', 'Our poverty levels are falling.', 'Our achievements are being globally recognised today.', 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.', 'Isn’t this incorrect?', 'I have a third vision.', 'India must stand up to the world.', 'Because I believe that unless India \\n               stands up to the world, no one will respect us.', 'Only strength respects strength.', 'We must be \\n               strong not only as a military power but also as an economic power.', 'Both must go hand-in-hand.', 'My good fortune was to have worked with three great minds.', 'Dr. Vikram Sarabhai of the Dept.', 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.', 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.', 'I see four milestones in my career']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')  \n",
    "\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "015cccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.',\n",
       " 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.',\n",
       " 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.',\n",
       " 'It is this freedom that\\n               we must protect and nurture and build on.',\n",
       " 'If we are not free, no one will respect us.',\n",
       " 'My second vision for India’s development.',\n",
       " 'For fifty years we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top 5 nations of the world\\n               in terms of GDP.',\n",
       " 'We have a 10 percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling.',\n",
       " 'Our achievements are being globally recognised today.',\n",
       " 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isn’t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India \\n               stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be \\n               strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b2c79a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "183e08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f4b4a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data path: ['/home/pc-1/nltk_data', '/home/pc-1/Desktop/NLP/.venv/nltk_data', '/home/pc-1/Desktop/NLP/.venv/share/nltk_data', '/home/pc-1/Desktop/NLP/.venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - '/home/pc-1/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/share/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m words = nltk.word_tokenize(paragraph)\n\u001b[32m     14\u001b[39m words = [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word.lower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(nltk.corpus.stopwords.words(\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m))]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m pos_tags = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(pos_tags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:168\u001b[39m, in \u001b[36mpos_tag\u001b[39m\u001b[34m(tokens, tagset, lang)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpos_tag\u001b[39m(tokens, tagset=\u001b[38;5;28;01mNone\u001b[39;00m, lang=\u001b[33m\"\u001b[39m\u001b[33meng\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    144\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m \u001b[33;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     tagger = \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:110\u001b[39m, in \u001b[36m_get_tagger\u001b[39m\u001b[34m(lang)\u001b[39m\n\u001b[32m    108\u001b[39m     tagger = PerceptronTagger(lang=lang)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     tagger = \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:180\u001b[39m, in \u001b[36mPerceptronTagger.__init__\u001b[39m\u001b[34m(self, load, lang, loc)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m.save_dir = path_join(\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.TRAINED_TAGGER_PATH, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.TAGGER_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:277\u001b[39m, in \u001b[36mPerceptronTagger.load_from_json\u001b[39m\u001b[34m(self, lang, loc)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33meng\u001b[39m\u001b[33m\"\u001b[39m, loc=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loc:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         loc = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_param\u001b[39m(json_file):\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_join(loc, json_file)) \u001b[38;5;28;01mas\u001b[39;00m fin:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - '/home/pc-1/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/share/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py:1185\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py:1056\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1053\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1060\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1062\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1063\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1071\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1072\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py:864\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    857\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    861\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    862\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    863\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    869\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py:776\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    766\u001b[39m         frames.append(\n\u001b[32m    767\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    768\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    773\u001b[39m             )\n\u001b[32m    774\u001b[39m         )\n\u001b[32m    775\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    778\u001b[39m     frames.append(\n\u001b[32m    779\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    780\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    785\u001b[39m         )\n\u001b[32m    786\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py:651\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/IPython/core/tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/stack_data/core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/stack_data/core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/stack_data/utils.py:164\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    161\u001b[39m             length += \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ttype, value\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m lexer = \u001b[43mMyLexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripnl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    166\u001b[39m     highlighted = pygments.highlight(code, lexer, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:660\u001b[39m, in \u001b[36mRegexLexerMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwds)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28mcls\u001b[39m._tokens = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_tokendef\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokendefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m.\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:599\u001b[39m, in \u001b[36mRegexLexerMeta.process_tokendef\u001b[39m\u001b[34m(cls, name, tokendefs)\u001b[39m\n\u001b[32m    597\u001b[39m tokendefs = tokendefs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokens[name]\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokendefs):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokendefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:579\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tdef) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwrong rule def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     rex = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muncompilable regex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:507\u001b[39m, in \u001b[36mRegexLexerMeta._process_regex\u001b[39m\u001b[34m(cls, regex, rflags, state)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Preprocess the regular expression component of a token definition.\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(regex, Future):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     regex = \u001b[43mregex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m re.compile(regex, rflags).match\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/lexer.py:495\u001b[39m, in \u001b[36mwords.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregex_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:91\u001b[39m, in \u001b[36mregex_opt\u001b[39m\u001b[34m(strings, prefix, suffix)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a compiled regex that matches any string in the given list.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;03mThe strings to match must be literal strings, not regexes.  They will be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m*prefix* and *suffix* are pre- and appended to the final regex.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     90\u001b[39m strings = \u001b[38;5;28msorted\u001b[39m(strings)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prefix + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m + suffix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:63\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# we have a prefix for all strings\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# print '-> prefix:', prefix\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + escape(prefix) \\\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplen\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     64\u001b[39m         + close_paren\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# is there a suffix?\u001b[39;00m\n\u001b[32m     66\u001b[39m strings_rev = [s[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:72\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     69\u001b[39m     slen = \u001b[38;5;28mlen\u001b[39m(suffix)\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# print '-> suffix:', suffix[::-1]\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[43mslen\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m     77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(regex_opt_inner(\u001b[38;5;28mlist\u001b[39m(group[\u001b[32m1\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "    \u001b[31m[... skipping similar frames: <genexpr> at line 77 (3 times), regex_opt_inner at line 77 (3 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:63\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# we have a prefix for all strings\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# print '-> prefix:', prefix\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + escape(prefix) \\\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplen\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     64\u001b[39m         + close_paren\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# is there a suffix?\u001b[39;00m\n\u001b[32m     66\u001b[39m strings_rev = [s[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:63\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# we have a prefix for all strings\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# print '-> prefix:', prefix\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + escape(prefix) \\\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplen\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \\\n\u001b[32m     64\u001b[39m         + close_paren\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# is there a suffix?\u001b[39;00m\n\u001b[32m     66\u001b[39m strings_rev = [s[::-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33;43m'\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/pygments/regexopt.py:36\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     33\u001b[39m first = strings[\u001b[32m0\u001b[39m]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(strings) == \u001b[32m1\u001b[39m:\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# print '-> only 1 string'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \u001b[43mescape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m)\u001b[49m + close_paren\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# print '-> first string empty'\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + regex_opt_inner(strings[\u001b[32m1\u001b[39m:], \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     40\u001b[39m         + \u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m'\u001b[39m + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/re/__init__.py:260\u001b[39m, in \u001b[36mescape\u001b[39m\u001b[34m(pattern)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03mEscape special characters in a string.\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pattern, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpattern\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_special_chars_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     pattern = \u001b[38;5;28mstr\u001b[39m(pattern, \u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('stopwords')  # For stopwords\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging\n",
    "\n",
    "print(\"NLTK data path:\", nltk.data.path)\n",
    "\n",
    "paragraph = \"This is an example paragraph. It contains multiple sentences. We will tokenize it.\"\n",
    "\n",
    "words = nltk.word_tokenize(paragraph)\n",
    "\n",
    "words = [word for word in words if word.lower() not in set(nltk.corpus.stopwords.words('english'))]\n",
    "\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f057b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taj', 'Mahal', 'is', 'a', 'beautiful', 'Monument']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 392\n"
     ]
    }
   ],
   "source": [
    "\"Taj Mahal is a beautiful Monument\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bf1855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pc-1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - '/home/pc-1/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/share/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mstopwords\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# For stopwords (if needed)\u001b[39;00m\n\u001b[32m      6\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33maveraged_perceptron_tagger\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# For POS tagging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTaj Mahal is a beautiful Monument\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:168\u001b[39m, in \u001b[36mpos_tag\u001b[39m\u001b[34m(tokens, tagset, lang)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpos_tag\u001b[39m(tokens, tagset=\u001b[38;5;28;01mNone\u001b[39;00m, lang=\u001b[33m\"\u001b[39m\u001b[33meng\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    144\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m \u001b[33;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     tagger = \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:110\u001b[39m, in \u001b[36m_get_tagger\u001b[39m\u001b[34m(lang)\u001b[39m\n\u001b[32m    108\u001b[39m     tagger = PerceptronTagger(lang=lang)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     tagger = \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:180\u001b[39m, in \u001b[36mPerceptronTagger.__init__\u001b[39m\u001b[34m(self, load, lang, loc)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m.save_dir = path_join(\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.TRAINED_TAGGER_PATH, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.TAGGER_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:277\u001b[39m, in \u001b[36mPerceptronTagger.load_from_json\u001b[39m\u001b[34m(self, lang, loc)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33meng\u001b[39m\u001b[33m\"\u001b[39m, loc=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loc:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         loc = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_param\u001b[39m(json_file):\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_join(loc, json_file)) \u001b[38;5;28;01mas\u001b[39;00m fin:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NLP/.venv/lib/python3.12/site-packages/nltk/data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - '/home/pc-1/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/share/nltk_data'\n    - '/home/pc-1/Desktop/NLP/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')  # For sentence and word tokenization\n",
    "nltk.download('stopwords')  # For stopwords (if needed)\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging\n",
    "\n",
    "print(nltk.pos_tag(\"Taj Mahal is a beautiful Monument\".split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
